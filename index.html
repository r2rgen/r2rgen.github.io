<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="R2RGen: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation">
    <meta name="author" content="Anonymous authors">

    <title>R2RGen: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>R2RGen: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation</h2>
<!--            <p class="abstract">An interpretable, data-efficient, and scalable neural scene representation.</p>-->
    <hr>
    <p>
        Anonymous Authors
        <br><br>
        <a href="https://github.com/r2rgen/" target="_blank" style="color: #1E90FF;">
            <img src="https://img.icons8.com/material-outlined/24/000000/github.png" alt="code" style="vertical-align: middle;">
            &nbsp;Code (GitHub)
        </a>
    </p>

</div>

<div class="container">

        <div class="vcontainer">
        <iframe class='video' src="https://www.youtube.com/embed/" frameborder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
        </div>

    <div class="section">
        <h2>Abstract</h2>
        <hr>
        <p>
            Towards the aim of generalized robotic manipulation, spatial generalization is the most fundamental capability that requires the policy to work robustly under different spatial distribution of objects, environment and agent. To achieve this, substantial human demonstrations need to be collected to cover different spatial configurations for training a generalized visuomotor policy via imitation learning. Prior works explore a promising direction that leverages data generation to acquire abundant spatially diverse data from minimal source demonstrations; however, most approaches remain confined to fixed-base manipulation and suffer from sim-to-real gap. In this paper, we propose a real-to-real 3D data generation framework (R2RGen) that directly modifies the pointcloud observation-action pairs to generate real-world data. R2RGen is simulator- and rendering-free, thus being efficient and plug-and-play. It also supports mobile robots, raw sensor inputs and any number of objects and interaction modes. Given one source demonstration, we design an annotation system for fine-grained scene / trajectory parsing in 30s. A group-wise augmentation strategy is proposed to address complex object combinations and task specifications, followed by a camera-aware processing method to align the distribution of generated data to 3D sensor.
        </p>
        <!-- add a image here-->
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/teaser.png" alt="pipeline" width="75%">
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Approach</h2>
        <hr>
        <p>
        	<b>Pre-processing results</b>. The 3D scene is parsed into complete objects, environment and robotâ€™s arm. The trajectory is parsed into interleaved motion and skill segments.
        </p>
        <!-- add a image here-->
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/pre-process.png" alt="pipeline" width="50%">
            </div>
        </div>
        <p>
        	<b>Pipeline of R2RGen</b>. Given processed source demonstration, we backtrack skills and apply group-wise augmentation to maintain the spatial relationships among target objects, where a fixed object set is maintained to judge whether the augmentation is applicable. Then motion planning is performed to generate trajectories that connect adjacent skills. After augmentation, we perform camera-aware processing to make the pointclouds follow distribution of RGB-D camera. The solid arrows indicate the processing flow, while the dashed arrows indicate the updating of fixed object set.
        </p>
        <!-- add a image here-->
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/augment-pipeline.png" alt="pipeline" width="100%">
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Visualization</h2>
        <hr>
        <p>
            We visualize xxxx
        </p>
        <!-- add a image here-->
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/vis-data.gif" alt="pipeline" width="90%">
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Experiments</h2>
        <hr>
        <p>
            We evaluate our method on xxxx
        </p>
    </div>

    <hr>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
